{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","toc_visible":true,"authorship_tag":"ABX9TyO/PkBupZqZVhb6i4XIcQLy"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"premium","accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Training Hyperonym Barba"],"metadata":{"id":"aj4dVjQ-mX9R"}},{"cell_type":"markdown","source":["This Colab notebook contains instructions on how to train a Hyperonym Barba model with public and private NLI datasets."],"metadata":{"id":"4NTDG6Bb-nlT"}},{"cell_type":"markdown","source":["## Mount Google Drive"],"metadata":{"id":"EQg1OVkQl19I"}},{"cell_type":"markdown","source":["Mount Google Drive to the local file system:"],"metadata":{"id":"D9B68F_vhR9u"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"gxVs3gYCfUqg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1674100937858,"user_tz":-480,"elapsed":18604,"user":{"displayName":"Yichao “Peak” Ji","userId":"01566227650798187810"}},"outputId":"3e819254-b8d9-454e-e1fb-190b5cb0356b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","source":["Change working directory into Google Drive:"],"metadata":{"id":"4AJNnJf2jfcd"}},{"cell_type":"code","source":["%mkdir -p /content/drive/MyDrive/hyperonym/barba\n","%cd /content/drive/MyDrive/hyperonym/barba"],"metadata":{"id":"_1KUQ0byfogU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1674100937859,"user_tz":-480,"elapsed":8,"user":{"displayName":"Yichao “Peak” Ji","userId":"01566227650798187810"}},"outputId":"976d725c-fa08-4faf-c554-2c5a61e55794"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/hyperonym/barba\n"]}]},{"cell_type":"markdown","source":["## Install dependencies"],"metadata":{"id":"mpVFv240nIDK"}},{"cell_type":"markdown","source":["Install TensorFlow:"],"metadata":{"id":"7Y99u9iXnesM"}},{"cell_type":"code","source":["!pip install tensorflow==2.11.0"],"metadata":{"id":"oaNL3CxrnFr_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Install Hugging Face libraries:"],"metadata":{"id":"MCjKqfo-nicR"}},{"cell_type":"code","source":["!pip install transformers datasets"],"metadata":{"id":"3YiIA125nbch"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Check if GPU is available:"],"metadata":{"id":"p8MCsVVQnxfr"}},{"cell_type":"code","source":["import tensorflow as tf\n","tf.test.gpu_device_name()"],"metadata":{"id":"d6bg0by7nxOI","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1674100998991,"user_tz":-480,"elapsed":4561,"user":{"displayName":"Yichao “Peak” Ji","userId":"01566227650798187810"}},"outputId":"69c77d2e-b100-466a-9351-af3e811718ac"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/device:GPU:0'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"id":"GN3f8bzzn5hq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1674100998991,"user_tz":-480,"elapsed":9,"user":{"displayName":"Yichao “Peak” Ji","userId":"01566227650798187810"}},"outputId":"eaffd550-bc58-4db5-dbf2-fd4d6283a375"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Thu Jan 19 04:03:18 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  A100-SXM4-40GB      Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   38C    P0    52W / 400W |    650MiB / 40536MiB |      7%      Default |\n","|                               |                      |             Disabled |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"markdown","source":["## Prepare datasets"],"metadata":{"id":"1rlIcWtZlWHg"}},{"cell_type":"code","source":["from datasets import load_dataset, concatenate_datasets, Features, Value, ClassLabel"],"metadata":{"id":"fMfSfqHHAmmv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Set number of processes to use for parallel operations:"],"metadata":{"id":"OBZ86bMupTrb"}},{"cell_type":"code","source":["num_proc = 12"],"metadata":{"id":"216RYhvTpfJz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["A typical NLI model generally has three output labels, namely `entailment`, `neutral` and `contradiction`.\n","\n","To support various private datasets, Barba uses only two labels, `entailment` and `not_entailment`:"],"metadata":{"id":"mxoNuQ73pq5w"}},{"cell_type":"code","source":["features = Features({\n","  'hypothesis': Value(dtype='string'),\n","  'premise': Value(dtype='string'),\n","  'label': ClassLabel(names=['entailment', 'not_entailment'])\n","})"],"metadata":{"id":"25jiDkp5p3Ai"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Function for removing redundant columns:"],"metadata":{"id":"d0sXYkWyylY-"}},{"cell_type":"code","source":["def strip_columns(dataset):\n","  columns = dataset[list(dataset)[0]].column_names\n","  columns = [col for col in columns if col not in features]\n","  return dataset.remove_columns(columns)"],"metadata":{"id":"L8nQKArexaN9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Function for squashing `neutral` and `contradiction` into a single label:"],"metadata":{"id":"s3wrJYZM3NhP"}},{"cell_type":"code","source":["def squash_labels(dataset):\n","  def fn(example):\n","    if example['label'] == 2:\n","      example['label'] = 1\n","    return example\n","  return dataset.map(fn, features=features, num_proc=num_proc)"],"metadata":{"id":"f_JfGJ6J3Db6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Load public datasets"],"metadata":{"id":"65uSJu7Rmy9g"}},{"cell_type":"markdown","source":["#### SNLI (Stanford Natural Language Inference)"],"metadata":{"id":"jHdASKgS2HXS"}},{"cell_type":"markdown","source":["The SNLI corpus (version 1.0) is a collection of 570k human-written English sentence pairs manually labeled for balanced classification with the labels entailment, contradiction, and neutral, supporting the task of natural language inference (NLI), also known as recognizing textual entailment (RTE)."],"metadata":{"id":"GS5nkcbC2N6t"}},{"cell_type":"code","source":["snli = load_dataset('snli')"],"metadata":{"id":"fmBkmaQY2QjY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["snli = strip_columns(snli)"],"metadata":{"id":"bIw7ecmt6Vz7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["snli = squash_labels(snli)"],"metadata":{"id":"iNeNQ6z64GMa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### XNLI (Cross-lingual Natural Language Inference)"],"metadata":{"id":"dnftJoeu7C_L"}},{"cell_type":"markdown","source":["The Cross-lingual Natural Language Inference (XNLI) corpus is the extension of the Multi-Genre NLI (MultiNLI) corpus to 15 languages. The dataset was created by manually translating the validation and test sets of MultiNLI into each of those 15 languages. The English training set was machine translated for all languages."],"metadata":{"id":"GNECIOSH7JSu"}},{"cell_type":"code","source":["xnli_zh = load_dataset('xnli', 'zh')"],"metadata":{"id":"ejcMzsrH7NN_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The Chinese subset of XNLI has whitespace between characters, we need to strip them before tokenization:"],"metadata":{"id":"LvinGkbJ8Doe"}},{"cell_type":"code","source":["def xnli_zh_fix(example):\n","  example['premise'] = example['premise'].replace(' ', '')\n","  example['hypothesis'] = example['hypothesis'].replace(' ', '')\n","  return example\n","xnli_zh = xnli_zh.map(xnli_zh_fix, num_proc=num_proc)"],"metadata":{"id":"yDKSKh598A3i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["xnli_zh = strip_columns(xnli_zh)"],"metadata":{"id":"26h0mIPi7qRk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["xnli_zh = squash_labels(xnli_zh)"],"metadata":{"id":"QvaEMoUr-VN-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### MultiNLI (Multi-Genre Natural Language Inference)"],"metadata":{"id":"HScMUITW4vYX"}},{"cell_type":"markdown","source":["The Multi-Genre Natural Language Inference (MultiNLI) corpus is a crowd-sourced collection of 433k sentence pairs annotated with textual entailment information. The corpus is modeled on the SNLI corpus, but differs in that covers a range of genres of spoken and written text, and supports a distinctive cross-genre generalization evaluation. The corpus served as the basis for the shared task of the RepEval 2017 Workshop at EMNLP in Copenhagen."],"metadata":{"id":"AS7yrGvV4x8v"}},{"cell_type":"code","source":["mnli = load_dataset('multi_nli')"],"metadata":{"id":"4Zhzp3QE4z6d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["mnli = strip_columns(mnli)"],"metadata":{"id":"PfzW_Mvf-j2v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["mnli = squash_labels(mnli)"],"metadata":{"id":"bNdU4lcK-lL7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### OCNLI (Original Chinese Natural Language Inference)"],"metadata":{"id":"x3pes9o6-1Uw"}},{"cell_type":"markdown","source":["OCNLI stands for Original Chinese Natural Language Inference. It is corpus for Chinese Natural Language Inference, collected following closely the procedures of MNLI, but with enhanced strategies aiming for more challenging inference pairs. We want to emphasize we did not use human/machine translation in creating the dataset, and thus our Chinese texts are original and not translated."],"metadata":{"id":"mJ-Bd-3e-35u"}},{"cell_type":"code","source":["ocnli = load_dataset('clue', 'ocnli')"],"metadata":{"id":"YzEb2r0B-5ng"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["OCNLI uses 0 as `neutral` and 1 as `entailment`, so we need to adjust the labels:"],"metadata":{"id":"k9L4pesJ_YDB"}},{"cell_type":"code","source":["def ocnli_fix(example):\n","  if example['label'] == 1:\n","    example['label'] = 0\n","  elif example['label'] == 0:\n","    example['label'] = 1\n","  return example\n","ocnli = ocnli.map(ocnli_fix, num_proc=num_proc)"],"metadata":{"id":"ywqu0_fU_d7F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ocnli = ocnli.rename_column('sentence1', 'premise')\n","ocnli = ocnli.rename_column('sentence2', 'hypothesis')"],"metadata":{"id":"b9nU-jct-_nH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ocnli = strip_columns(ocnli)"],"metadata":{"id":"2J4nxnXj_PuR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ocnli = squash_labels(ocnli)"],"metadata":{"id":"y2fcxW5B_TmN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### ANLI (Adversarial Natural Language Inference)"],"metadata":{"id":"gYWiXkhOA_ga"}},{"cell_type":"markdown","source":["The Adversarial Natural Language Inference (ANLI) is a new large-scale NLI benchmark dataset, The dataset is collected via an iterative, adversarial human-and-model-in-the-loop procedure. ANLI is much more difficult than its predecessors including SNLI and MNLI. It contains three rounds. Each round has train/dev/test splits."],"metadata":{"id":"Vgx8AcAvBCei"}},{"cell_type":"code","source":["anli = load_dataset('anli')"],"metadata":{"id":"GqN8JkpjBF3o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["anli = strip_columns(anli)"],"metadata":{"id":"j4XQMg_iBKNM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["anli = squash_labels(anli)"],"metadata":{"id":"pz_KSJqnBLIN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Group public datasets"],"metadata":{"id":"VJMWZd7m1zLG"}},{"cell_type":"code","source":["public_train_datasets = [\n","  snli['train'],\n","  xnli_zh['train'],\n","  mnli['train'],\n","  ocnli['train'],\n","  anli['train_r1']\n","]\n","public_validation_datasets = [\n","  snli['validation'],\n","  xnli_zh['validation'],\n","  mnli['validation_matched'],\n","  ocnli['validation'],\n","  anli['dev_r1']\n","]"],"metadata":{"id":"FJ6bvyXS1rb-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Load private datasets"],"metadata":{"id":"IrkFCJRDm-Fj"}},{"cell_type":"markdown","source":["Try to load private datasets in the `datasets` directory:"],"metadata":{"id":"1f8iYnVSuF63"}},{"cell_type":"code","source":["import os\n","private_train_datasets = []\n","private_validation_datasets = []\n","if os.path.isdir('datasets'):\n","  try:\n","    private_dataset = load_dataset('./datasets')\n","    private_dataset = strip_columns(private_dataset)\n","    private_dataset = squash_labels(private_dataset)\n","    if 'train' in private_dataset:\n","      private_train_datasets.append(private_dataset['train'])\n","    if 'validation' in private_dataset:\n","      private_validation_datasets.append(private_dataset['validation'])\n","  except FileNotFoundError:\n","    pass"],"metadata":{"id":"2qq8CuALrg6X"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Concatenate datasets"],"metadata":{"id":"hyF720CJ0EbQ"}},{"cell_type":"code","source":["train_dataset = concatenate_datasets(public_train_datasets + private_train_datasets)\n","validation_dataset = concatenate_datasets(public_validation_datasets + private_validation_datasets)"],"metadata":{"id":"IIDUOpeW0G2o"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Filter datasets"],"metadata":{"id":"mmzqJjtFE53i"}},{"cell_type":"code","source":["def filter(dataset):\n","  def fn(example):\n","    if example['label'] < 0 or example['label'] > 1:\n","      return False\n","    if len(example['hypothesis']) == 0:\n","      return False\n","    if len(example['premise']) == 0:\n","      return False\n","    return True\n","  return dataset.filter(fn, num_proc=num_proc)"],"metadata":{"id":"4kszr58BGSWg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dataset = filter(train_dataset)\n","validation_dataset = filter(validation_dataset)"],"metadata":{"id":"U1keXkPiGVQE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Tokenize datasets"],"metadata":{"id":"OiqY6fKcpNcF"}},{"cell_type":"markdown","source":["Load pretrained tokenizer for XLM-RoBERTa:"],"metadata":{"id":"QPMGou9fG7YN"}},{"cell_type":"code","source":["from transformers import AutoTokenizer\n","tokenizer = AutoTokenizer.from_pretrained('xlm-roberta-base')"],"metadata":{"id":"XH8bOFxAG7DX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Test tokenization using examples from the [original implementation](https://github.com/facebookresearch/XLM#ii-cross-lingual-language-model-pretraining-xlm):"],"metadata":{"id":"qVx81lswHG4J"}},{"cell_type":"code","source":["print(tokenizer('Hello world!')) # [0, 35378,  8999, 38, 2]\n","print(tokenizer('你好，世界')) # [0, 6, 124084, 4, 3221, 2]\n","print(tokenizer('a', 'b', padding='max_length')) # [0, 10, 2, 2, 876, 2, 1, 1, 1, ..., 1]"],"metadata":{"id":"-miUsvShHHbd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1674101190162,"user_tz":-480,"elapsed":10,"user":{"displayName":"Yichao “Peak” Ji","userId":"01566227650798187810"}},"outputId":"9da88dce-21a3-4b7c-8209-93dd355b3ec2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'input_ids': [0, 35378, 8999, 38, 2], 'attention_mask': [1, 1, 1, 1, 1]}\n","{'input_ids': [0, 6, 124084, 4, 3221, 2], 'attention_mask': [1, 1, 1, 1, 1, 1]}\n","{'input_ids': [0, 10, 2, 2, 876, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"]}]},{"cell_type":"code","source":["def tokenize(dataset):\n","  def fn(examples):\n","    return tokenizer(examples['hypothesis'], examples['premise'], truncation='only_second')\n","  return dataset.map(fn, batched=True, num_proc=num_proc)"],"metadata":{"id":"66DahiuwDpwK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dataset = tokenize(train_dataset)\n","validation_dataset = tokenize(validation_dataset)"],"metadata":{"id":"_8Rbld22HyOV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Fine-tune model"],"metadata":{"id":"SsfZ8qrUIiMB"}},{"cell_type":"markdown","source":["Set hyperparameters based on [XNLI tasks for XLM-RoBERTa](https://github.com/facebookresearch/fairseq/issues/1367#issuecomment-555609917):"],"metadata":{"id":"OEFdeeMbIqwD"}},{"cell_type":"code","source":["learning_rate = 7.5e-6\n","batch_size = 16\n","num_epochs = 3"],"metadata":{"id":"BtTdRlE3Ikko"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Load pretrained model:"],"metadata":{"id":"01ZSy1H0JA6j"}},{"cell_type":"code","source":["from transformers import TFAutoModelForSequenceClassification\n","model = TFAutoModelForSequenceClassification.from_pretrained('xlm-roberta-base', num_labels=2)\n","model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate), metrics=['accuracy'])"],"metadata":{"id":"IQPTEnkDJBeu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Convert datasets into TensorFlow format:"],"metadata":{"id":"QAA1Qe4SJkaR"}},{"cell_type":"code","source":["tf_train_dataset = model.prepare_tf_dataset(train_dataset, shuffle=True, batch_size=batch_size, tokenizer=tokenizer)\n","tf_validation_dataset = model.prepare_tf_dataset(validation_dataset, shuffle=False, batch_size=batch_size, tokenizer=tokenizer)"],"metadata":{"id":"v47Q3IhkJvLq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Create callback for early stopping:"],"metadata":{"id":"bvel6ES2J6Gf"}},{"cell_type":"code","source":["callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=1)"],"metadata":{"id":"bKfSLTQ9J66R"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Fine-tune the pretrained model:"],"metadata":{"id":"TaItetfQJ8zX"}},{"cell_type":"code","source":["model.fit(tf_train_dataset, validation_data=tf_validation_dataset, epochs=num_epochs, callbacks=[callback])"],"metadata":{"id":"2bokxMUFKAcX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1674125216076,"user_tz":-480,"elapsed":23882257,"user":{"displayName":"Yichao “Peak” Ji","userId":"01566227650798187810"}},"outputId":"db50c516-004d-4fe3-901f-63a8cd11173d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/3\n","96110/96110 [==============================] - 8039s 83ms/step - loss: 0.2934 - accuracy: 0.8756 - val_loss: 0.2704 - val_accuracy: 0.8886\n","Epoch 2/3\n","96110/96110 [==============================] - 7848s 82ms/step - loss: 0.2316 - accuracy: 0.9050 - val_loss: 0.2615 - val_accuracy: 0.8970\n","Epoch 3/3\n","96110/96110 [==============================] - 7995s 83ms/step - loss: 0.2022 - accuracy: 0.9185 - val_loss: 0.2730 - val_accuracy: 0.8960\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fd9c7c31bb0>"]},"metadata":{},"execution_count":43}]},{"cell_type":"markdown","source":["## Save model"],"metadata":{"id":"U-4CaUrIKR4R"}},{"cell_type":"code","source":["%mkdir -p models"],"metadata":{"id":"XUOiuq8jKYST"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Save the trained model to Google Drive:"],"metadata":{"id":"eV3alig-Kjjl"}},{"cell_type":"code","source":["tf.saved_model.save(model, 'models/barba')"],"metadata":{"id":"ebTT5k9vKkb6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Flush and unmount Google Drive:"],"metadata":{"id":"1FHWihfdKwNA"}},{"cell_type":"code","source":["drive.flush_and_unmount()"],"metadata":{"id":"AJTJblZ6KxyU"},"execution_count":null,"outputs":[]}]}
